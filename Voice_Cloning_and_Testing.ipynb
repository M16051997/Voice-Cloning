{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "as92SU0ZSKtq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Tortoice/tortoise-tts/Tortoise-tts-voice-clone')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Building Voice Cloning On Pretrained Tortoice Model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJMGbCvHSzll"
      },
      "outputs": [],
      "source": [
        "!pip install -r /content/drive/MyDrive/Tortoice/tortoise-tts/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pVaE1iYWuOf",
        "outputId": "a9ede79a-05a1-47f2-a60b-ddb3d633e12c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (1.10.12)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic) (4.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install pydantic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBUV4xr6XDn0"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision torchaudio -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnWvOvtXZBpP",
        "outputId": "a59b3ccb-66b7-4add-b8a1-b5530f023110"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Tortoise-tts-voice-clone'...\n",
            "remote: Enumerating objects: 634, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 634 (delta 5), reused 2 (delta 0), pack-reused 622\u001b[K\n",
            "Receiving objects: 100% (634/634), 60.40 MiB | 18.42 MiB/s, done.\n",
            "Resolving deltas: 100% (5/5), done.\n",
            "Updating files: 100% (576/576), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/neonbjb/tortoise-tts.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BF4OIycpUoXD"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torchaudio\n",
        "import tortoise\n",
        "from tortoise import api\n",
        "\n",
        "from tortoise import api\n",
        "from tortoise.api import TextToSpeech, MODELS_DIR\n",
        "\n",
        "from tortoise import utils\n",
        "\n",
        "from tortoise.utils.audio import load_voices, load_voice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtRsScyyrePW"
      },
      "outputs": [],
      "source": [
        "!pip install transformers==4.29.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Ar4r00P1bTCi"
      },
      "outputs": [],
      "source": [
        "# This is the text that will be spoken.\n",
        "text = \"\"\"\n",
        "In the pursuit of success, one must be willing to make sacrifices.,\n",
        "It is through these sacrifices that we kindle the flame of determination, propelling ourselves towards greatness.,\n",
        "Each sacrifice serves as a testament to our commitment and unwavering focus on our goals.,\"\"\"\n",
        "\n",
        "# Pick a \"preset mode\" to determine quality. Options: {\"ultra_fast\", \"fast\" (default), \"standard\", \"high_quality\"}. See docs in api.py\n",
        "preset = \"fast\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsbMqhRUrO2g",
        "outputId": "dfd784a6-055f-4e6d-c490-724b613a79ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4.29.2\n"
          ]
        }
      ],
      "source": [
        "import transformers\n",
        "\n",
        "print(transformers.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vk0zLoEDbXCO",
        "outputId": "99423e9c-27cb-45ba-cb2a-de896a508e8a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0% |                                                                        |\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading diffusion_decoder.pth from https://huggingface.co/jbetker/tortoise-tts-v2/resolve/main/.models/diffusion_decoder.pth...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0% |                                                                        |\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading clvp2.pth from https://huggingface.co/jbetker/tortoise-tts-v2/resolve/main/.models/clvp2.pth...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0% |                                                                        |\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading vocoder.pth from https://huggingface.co/jbetker/tortoise-tts-v2/resolve/main/.models/vocoder.pth...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done.\n"
          ]
        }
      ],
      "source": [
        "tts = TextToSpeech()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "###  Voice Cloning\n",
        "\n",
        "voice_samples, conditioning_latents = load_voice('my_voice') # In My_Voice folder I inserted my voice record of 3 wav files\n",
        "\n",
        "# Cloning the voice and generating the Sample of my voice with text\n",
        "gen = tts.tts_with_preset(text, voice_samples=voice_samples, conditioning_latents=conditioning_latents,\n",
        "                          preset=preset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPQeQ_tgp-Rf",
        "outputId": "d4c1e9e8-2c84-4e1c-b410-a0b14ae21d68"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Tortoice/tortoise-tts/Tortoise-tts-voice-clone/tortoise/utils/audio.py:17: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
            "  sampling_rate, data = read(full_path)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating autoregressive samples..\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6/6 [1:06:36<00:00, 666.12s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing best candidates using CLVP\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6/6 [00:06<00:00,  1.11s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transforming autoregressive outputs into audio..\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 80/80 [00:59<00:00,  1.34it/s]\n"
          ]
        }
      ],
      "source": [
        "# Save the Cloned Voice\n",
        "\n",
        "torchaudio.save(f'generated-voice4.wav', gen.squeeze(0).cpu(), 24000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "LVmoU1IwnORf"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "wXajCmv4nsKV"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
